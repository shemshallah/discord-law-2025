
#!/usr/bin/env python3
"""
FINAL VALIDATION: DISCORD DECAY LAW
====================================
One last comprehensive validation before publication

OBJECTIVES:
1. Confirm cos²() law holds for N=4,6,8
2. Tighten error bars (5 reps per config)
3. Validate decoherence model
4. Generate publication-quality dataset

PROTOCOL:
- System sizes: N = 4, 6, 8
- Angles:  = [0, 22.5, 45, 67.5, 90] (5 angles, symmetric)
- Repetitions: 4 per configuration
- Total: 3 × 5 × 4 = 60 measurements
- Runtime: ~12 minutes at 12 sec/measurement
"""

import numpy as np
from qiskit import QuantumCircuit, transpile
from azure.quantum import Workspace
from azure.quantum.qiskit import AzureQuantumProvider
import time
import warnings
from scipy.stats import entropy
from scipy.optimize import curve_fit
import csv
warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURATION
# ============================================================================
CONNECTION_STRING = "SubscriptionId=xxx;ResourceGroupName=xxx;WorkspaceName=xxx;ApiKey=xxx;QuantumEndpoint=https://westus.quantum.azure.com/;"
MAX_RUNTIME = 15 * 60
SHOTS = 2000

print("="*80)
print("   FINAL VALIDATION: DISCORD DECAY LAW")
print("="*80)
print("\n Publication-Quality Dataset")
print("   D() = A·cos²() + B")
print("\nObjectives:")
print("  1. Validate cos²() law for N=4,6,8")
print("  2. Quantify decoherence (A,B parameters)")
print("  3. Generate figures for manuscript")
print("  4. 60 measurements in ~12 minutes")
print("="*80 + "\n")

# ============================================================================
# BACKEND
# ============================================================================
workspace = Workspace.from_connection_string(CONNECTION_STRING)
provider = AzureQuantumProvider(workspace)
backend = None

for b in provider.backends():
    if 'rigetti' in b.name.lower() and 'qvm' in b.name.lower():
        backend = provider.get_backend(b.name)
        print(f" Connected: {b.name}\n")
        break

if not backend:
    raise RuntimeError("Rigetti QVM not found!")

start_time = time.time()

# ============================================================================
# CIRCUIT DESIGN
# ============================================================================

def create_chimera_circuit(n_qubits, theta_deg):
    """Optimized chimera circuit"""
    qc = QuantumCircuit(n_qubits, n_qubits)
    theta = np.radians(theta_deg)
    
    # GHZ preparation
    qc.h(0)
    for i in range(min(n_qubits-1, 4)):  # Limit entangling for speed
        qc.cx(i, i+1)
    
    # Parametric rotation
    qc.ry(theta, 0)
    if n_qubits > 1:
        qc.ry(theta/2, 1)
    
    qc.measure(range(n_qubits), range(n_qubits))
    return qc

# ============================================================================
# ANALYSIS
# ============================================================================

def calculate_discord(counts, n_qubits):
    """Calculate quantum discord"""
    from collections import defaultdict
    
    total_shots = sum(counts.values())
    counts_0 = defaultdict(int)
    counts_1 = defaultdict(int)
    
    for bitstring, count in counts.items():
        bits = bitstring[::-1]
        if len(bits) >= n_qubits:
            if bits[0] == '0':
                counts_0[bits[1:]] += count
            else:
                counts_1[bits[1:]] += count
    
    total_0 = sum(counts_0.values())
    total_1 = sum(counts_1.values())
    
    if total_0 == 0 or total_1 == 0:
        return 0.0
    
    p_0 = total_0 / total_shots
    p_1 = total_1 / total_shots
    
    def calc_entropy(counts_dict, total):
        if total == 0:
            return 0
        probs = [c/total for c in counts_dict.values() if c > 0]
        return entropy(probs, base=2) if len(probs) > 0 else 0
    
    H_0 = calc_entropy(counts_0, total_0)
    H_1 = calc_entropy(counts_1, total_1)
    
    all_subsystem = defaultdict(int)
    for bitstring, count in counts.items():
        bits = bitstring[::-1]
        if len(bits) >= n_qubits:
            all_subsystem[bits[1:]] += count
    
    H_total = calc_entropy(all_subsystem, total_shots)
    discord = H_total - (p_0 * H_0 + p_1 * H_1)
    
    return max(0, discord)

def calculate_steering(counts):
    """Steering parameter"""
    total = sum(counts.values())
    even = sum(count for bits, count in counts.items() if bits.count('1') % 2 == 0)
    return abs(2*even/total - 1)

def calculate_witnesses(counts, n_qubits):
    """Entanglement witnesses"""
    total = sum(counts.values())
    probs = {k: v/total for k, v in counts.items()}
    
    all_zeros = '0' * n_qubits
    all_ones = '1' * n_qubits
    p_ghz = probs.get(all_zeros, 0) + probs.get(all_ones, 0)
    
    return {
        'ghz_fidelity': p_ghz,
        'coherence': p_ghz / 1.0  # Normalized
    }

# ============================================================================
# MAIN EXPERIMENT
# ============================================================================

def run_final_validation():
    """Execute 60-measurement validation"""
    
    print("="*80)
    print("FINAL VALIDATION SUITE")
    print("="*80)
    
    # Strategic angle selection (symmetric around 45°)
    angles = [0, 22.5, 45, 67.5, 90]
    system_sizes = [4, 6, 8]
    repetitions = 4
    
    total_measurements = len(angles) * len(system_sizes) * repetitions
    
    print(f"\nConfiguration:")
    print(f"  System sizes: {system_sizes}")
    print(f"  Angles: {angles}")
    print(f"  Repetitions: {repetitions}")
    print(f"  Total: {total_measurements} measurements")
    print(f"  Target time: ~12 minutes\n")
    
    results = []
    measurement_count = 0
    
    for n in system_sizes:
        print(f"\n{'='*80}")
        print(f"SYSTEM SIZE: N = {n} qubits")
        print(f"{'='*80}\n")
        
        for theta in angles:
            elapsed = time.time() - start_time
            if elapsed > MAX_RUNTIME:
                print("\n  Time limit reached")
                break
            
            print(f" = {theta:5.1f}°  ", end='', flush=True)
            
            rep_data = {
                'discords': [],
                'steerings': [],
                'fidelities': [],
                'times': []
            }
            
            for rep in range(repetitions):
                try:
                    t0 = time.time()
                    
                    # Create and execute
                    qc = create_chimera_circuit(n, theta)
                    qc_trans = transpile(qc, backend=backend, optimization_level=3)
                    
                    job = backend.run(qc_trans, shots=SHOTS)
                    counts = job.result().get_counts()
                    
                    # Calculate observables
                    discord = calculate_discord(counts, n)
                    steering = calculate_steering(counts)
                    witnesses = calculate_witnesses(counts, n)
                    
                    t1 = time.time()
                    
                    # Store
                    results.append({
                        'n_qubits': n,
                        'theta': theta,
                        'repetition': rep,
                        'discord': discord,
                        'steering': steering,
                        'ghz_fidelity': witnesses['ghz_fidelity'],
                        'coherence': witnesses['coherence'],
                        'time_sec': t1 - t0
                    })
                    
                    rep_data['discords'].append(discord)
                    rep_data['steerings'].append(steering)
                    rep_data['fidelities'].append(witnesses['ghz_fidelity'])
                    rep_data['times'].append(t1 - t0)
                    
                    measurement_count += 1
                    print(".", end='', flush=True)
                    
                except Exception as e:
                    print("E", end='', flush=True)
            
            # Print statistics
            if rep_data['discords']:
                mean_d = np.mean(rep_data['discords'])
                std_d = np.std(rep_data['discords'])
                mean_s = np.mean(rep_data['steerings'])
                mean_f = np.mean(rep_data['fidelities'])
                mean_t = np.mean(rep_data['times'])
                
                print(f"  D={mean_d:.4f}±{std_d:.4f}  S={mean_s:.3f}  F={mean_f:.3f}  ({mean_t:.1f}s)")
    
    print(f"\n{'='*80}")
    print(f" Validation complete: {measurement_count}/{total_measurements} measurements")
    print(f" Runtime: {(time.time()-start_time)/60:.1f} minutes")
    print(f"{'='*80}")
    
    return results

# ============================================================================
# ANALYSIS & FITTING
# ============================================================================

def analyze_and_fit(results):
    """Comprehensive analysis with publication-quality outputs"""
    
    print("\n" + "="*80)
    print("STATISTICAL ANALYSIS & FITTING")
    print("="*80)
    
    system_sizes = sorted(set(r['n_qubits'] for r in results))
    
    fit_results = {}
    
    for n in system_sizes:
        n_data = [r for r in results if r['n_qubits'] == n]
        
        if not n_data:
            continue
        
        print(f"\n{''*80}")
        print(f"N = {n} QUBITS")
        print(f"{''*80}")
        
        # Aggregate by angle
        angles = sorted(set(r['theta'] for r in n_data))
        
        stats = {}
        for theta in angles:
            theta_data = [r for r in n_data if r['theta'] == theta]
            discords = [r['discord'] for r in theta_data]
            steerings = [r['steering'] for r in theta_data]
            
            stats[theta] = {
                'discord_mean': np.mean(discords),
                'discord_std': np.std(discords),
                'discord_sem': np.std(discords) / np.sqrt(len(discords)),
                'steering_mean': np.mean(steerings),
                'count': len(discords)
            }
        
        # Print table
        print(f"\n{'Angle':>8} {'Discord':>12} {'SEM':>8} {'Steering':>10} {'N':>5}")
        print("" * 50)
        for theta in angles:
            s = stats[theta]
            print(f"{theta:>6.1f}°  {s['discord_mean']:>10.4f}  ±{s['discord_sem']:.4f}  {s['steering_mean']:>8.3f}  {s['count']:>4}")
        
        # Fit cos²() model
        print(f"\nFITTING: D() = A·cos²() + B")
        print("" * 50)
        
        thetas_arr = np.array(angles)
        means_arr = np.array([stats[t]['discord_mean'] for t in angles])
        sems_arr = np.array([stats[t]['discord_sem'] for t in angles])
        
        def model(theta, A, B):
            return A * np.cos(np.radians(theta))**2 + B
        
        try:
            popt, pcov = curve_fit(
                model,
                thetas_arr,
                means_arr,
                p0=[1.0, 0.0],
                sigma=sems_arr,
                absolute_sigma=True
            )
            
            A, B = popt
            A_err, B_err = np.sqrt(np.diag(pcov))
            
            # Calculate goodness of fit
            residuals = means_arr - model(thetas_arr, *popt)
            ss_res = np.sum(residuals**2)
            ss_tot = np.sum((means_arr - np.mean(means_arr))**2)
            r_squared = 1 - (ss_res / ss_tot)
            
            # Chi-squared
            chi_squared = np.sum((residuals / sems_arr)**2)
            dof = len(thetas_arr) - 2
            reduced_chi_sq = chi_squared / dof
            
            print(f"\nPARAMETERS:")
            print(f"  A = {A:.6f} ± {A_err:.6f}")
            print(f"  B = {B:.6f} ± {B_err:.6f}")
            print(f"\nGOODNESS OF FIT:")
            print(f"  R² = {r_squared:.6f}")
            print(f"  ²/dof = {reduced_chi_sq:.4f}")
            
            # Physical interpretation
            print(f"\nPHYSICAL INTERPRETATION:")
            decoherence = (1 - A) * 100
            offset = abs(B)
            print(f"  Decoherence loss: {decoherence:.2f}%")
            print(f"  Residual discord: {offset:.4f}")
            
            # Quality assessment
            if r_squared > 0.98 and abs(A - 1.0) < 0.05 and abs(B) < 0.02:
                quality = " EXCELLENT - Nature Physics quality"
            elif r_squared > 0.95 and abs(A - 1.0) < 0.10:
                quality = " VERY GOOD - PRL/PRA quality"
            elif r_squared > 0.90:
                quality = " GOOD - PRA quality"
            else:
                quality = " ACCEPTABLE - More data recommended"
            
            print(f"\nQUALITY: {quality}")
            
            # Store results
            fit_results[n] = {
                'A': A, 'A_err': A_err,
                'B': B, 'B_err': B_err,
                'R2': r_squared,
                'chi2_dof': reduced_chi_sq,
                'decoherence': decoherence,
                'quality': quality
            }
            
            # Predictions
            print(f"\nPREDICTIONS:")
            for test_theta in [0, 30, 45, 60, 90]:
                predicted = model(test_theta, A, B)
                theory = np.cos(np.radians(test_theta))**2
                deviation = (predicted - theory) * 100
                print(f"  ={test_theta:2d}°: D={predicted:.4f} (theory={theory:.4f}, deviation={deviation:+.1f}%)")
            
        except Exception as e:
            print(f"  Fitting failed: {e}")
            fit_results[n] = None
    
    # Cross-system comparison
    if len(fit_results) > 1:
        print(f"\n{'='*80}")
        print("CROSS-SYSTEM COMPARISON")
        print(f"{'='*80}\n")
        
        print(f"{'N':>4} {'A':>10} {'B':>10} {'R²':>8} {'Decoherence':>12}")
        print("" * 50)
        for n in sorted(fit_results.keys()):
            if fit_results[n]:
                f = fit_results[n]
                print(f"{n:>4} {f['A']:>10.6f} {f['B']:>10.6f} {f['R2']:>8.6f} {f['decoherence']:>10.2f}%")
        
        # Test for universality
        A_values = [fit_results[n]['A'] for n in fit_results.keys() if fit_results[n]]
        if len(A_values) > 1:
            A_range = max(A_values) - min(A_values)
            if A_range < 0.05:
                print(f"\n UNIVERSAL: A varies by only {A_range:.4f} across system sizes")
                print(f"   cos²() law is SCALE-INVARIANT")
            else:
                print(f"\n  System-size dependence detected: A = {A_range:.4f}")
    
    return fit_results

# ============================================================================
# PUBLICATION READINESS
# ============================================================================

def publication_assessment(results, fit_results):
    """Assess publication readiness"""
    
    print("\n" + "="*80)
    print("PUBLICATION READINESS ASSESSMENT")
    print("="*80)
    
    criteria = {
        'measurements': len(results) >= 50,
        'system_sizes': len(set(r['n_qubits'] for r in results)) >= 3,
        'angles': len(set(r['theta'] for r in results)) >= 5,
        'repetitions': all(
            len([r for r in results if r['n_qubits']==n and r['theta']==t]) >= 3
            for n in set(r['n_qubits'] for r in results)
            for t in set(r['theta'] for r in results if r['n_qubits']==n)
        ),
        'excellent_fit': any(f and f['R2'] > 0.95 for f in fit_results.values() if f),
        'universality': len(fit_results) >= 2 and all(
            f and abs(f['A'] - 1.0) < 0.10 for f in fit_results.values() if f
        )
    }
    
    print("\nCRITERIA:")
    print("" * 50)
    for criterion, passed in criteria.items():
        status = "" if passed else ""
        print(f"  {status} {criterion.replace('_', ' ').title()}")
    
    score = sum(criteria.values())
    total = len(criteria)
    
    print(f"\nSCORE: {score}/{total}")
    
    if score == total:
        verdict = " PUBLICATION READY - Submit to Phys Rev A immediately"
    elif score >= total - 1:
        verdict = " NEARLY READY - Minor improvements suggested"
    elif score >= total - 2:
        verdict = " NEEDS WORK - Additional measurements recommended"
    else:
        verdict = " NOT READY - Significant issues to address"
    
    print(f"\nVERDICT: {verdict}")
    
    print(f"\n{'='*80}")
    print("RECOMMENDED NEXT STEPS")
    print(f"{'='*80}")
    
    if score >= total - 1:
        print("\n1. Generate figures (Discord vs  for each N)")
        print("2. Write manuscript draft")
        print("3. Submit to arXiv within 1 week")
        print("4. Target Physical Review A")
        print("5. Prepare response to reviewers")
    else:
        print("\n1. Run additional measurements for weak areas")
        print("2. Increase repetitions for tighter error bars")
        print("3. Add more system sizes if N<3")
        print("4. Rerun validation suite")

# ============================================================================
# MAIN
# ============================================================================

def main():
    print("="*80)
    print("STARTING FINAL VALIDATION")
    print("="*80 + "\n")
    
    # Run experiment
    results = run_final_validation()
    
    # Save raw data
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    csv_filename = f'final_validation_{timestamp}.csv'
    
    if results:
        with open(csv_filename, 'w', newline='') as f:
            writer = csv.DictWriter(f, fieldnames=results[0].keys())
            writer.writeheader()
            writer.writerows(results)
        print(f"\n Raw data saved: {csv_filename}")
    
    # Analyze and fit
    fit_results = analyze_and_fit(results)
    
    # Publication assessment
    publication_assessment(results, fit_results)
    
    # Final summary
    total_time = (time.time() - start_time) / 60
    print(f"\n{'='*80}")
    print("FINAL VALIDATION COMPLETE")
    print(f"{'='*80}")
    print(f"Total measurements: {len(results)}")
    print(f"Runtime: {total_time:.1f} minutes")
    print(f"Data file: {csv_filename}")
    print(f"{'='*80}\n")

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\n  Interrupted")
    except Exception as e:
        print(f"\n\n Error: {e}")
        import traceback
        traceback.print_exc()
